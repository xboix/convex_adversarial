{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "juvenile-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"vision\"\n",
    "results_dir = '/om2/user/xboix/robustness/convex_robustness/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "renewable-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 config files created\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "    \n",
    "import runs.config_experiments_vision as run\n",
    "experiment_list = run.config_experiments(results_dir, create_json=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "certified-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_attacks = [\"l1_pgd_norm\", \"l1_fgm_norm\", \"linf_pgd\", \"l2_pgd_norm\", \"linf_fgsm\", \"l2_fgm_norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minimal-singapore",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing!! /om2/user/xboix/robustness/convex_robustness/0/results/acc_val_bound.pkl\n",
      "dict_keys([0.0, 0.0056, 0.014, 0.0224, 0.028, 0.042, 0.056, 0.084, 0.28, 2.8000000000000003, 8.4, 14.0, 28.0, 56.0, 140.0, 280.0, 420.0, 560.0, 840.0, 1400.0])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ThreeLayer'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     56\u001B[0m     ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackbone\u001B[39m\u001B[38;5;124m\"\u001B[39m][backbone]) \u001B[38;5;241m&\u001B[39m \n\u001B[1;32m     57\u001B[0m                \u001B[38;5;28mset\u001B[39m(parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrobust_training\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;28;01mFalse\u001B[39;00m]))\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 59\u001B[0m     ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(\u001B[43mparameters\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbackbone\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbackbone\u001B[49m\u001B[43m]\u001B[49m) \u001B[38;5;241m&\u001B[39m \n\u001B[1;32m     60\u001B[0m            \u001B[38;5;28mset\u001B[39m(parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrobust_training\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;28;01mTrue\u001B[39;00m])\u001B[38;5;241m&\u001B[39m\n\u001B[1;32m     61\u001B[0m           \u001B[38;5;28mset\u001B[39m(parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype_robust\u001B[39m\u001B[38;5;124m\"\u001B[39m][type_robust]))\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backbone \u001B[38;5;241m==\u001B[39m net \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m+pgd\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m robust_training \u001B[38;5;241m==\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'ThreeLayer'"
     ]
    }
   ],
   "source": [
    "\n",
    "list_entries = []\n",
    "for net in ['ThreeLayer']:\n",
    "    for dataset_id,dataset_name in zip([0,66,67],['MNIST','Fashion', 'CIFAR']):\n",
    "\n",
    "        #Find an experiment of the dataset_id to get the epsilons\n",
    "        for idx,_ in enumerate(experiment_list):\n",
    "            if experiment_list[idx]['data_set_id'] == dataset_id: \n",
    "                break\n",
    "        \n",
    "        for attack in name_attacks:\n",
    "\n",
    "            file_name = results_dir + experiment_list[idx]['model_name'] + '/results/acc_' + 'val' + '_' + attack + '.pkl'\n",
    "            if not os.path.isfile(file_name):\n",
    "                print(\"Missing!! \" + file_name)\n",
    "                continue\n",
    "            with open(file_name, 'rb') as f:\n",
    "                tmp = pickle.load(f)\n",
    "                \n",
    "            print(tmp.keys())\n",
    "\n",
    "            for idx_epsilon, cv_epsilon in enumerate(list(tmp.keys())):\n",
    "                # Hash table of parameters\n",
    "                parameters = {\"epsilon\": {}, \"standarize\": {}, \"backbone\": {}, \"initial_learning_rate\": {}, \n",
    "                              \"robust_training\": {}, \"type_robust\": {}, \"epsilon_pgd_training\":{}}\n",
    "\n",
    "                to_exclude = [0]\n",
    "                experiment_list_tmp = [element for i, element in enumerate(experiment_list) if i not in to_exclude]\n",
    "                for exp in experiment_list_tmp:\n",
    "                    if not exp['data_set'] == dataset_id: \n",
    "                        continue\n",
    "                    for kk in parameters.keys():\n",
    "                        if exp[kk] in parameters[kk]:\n",
    "                            parameters[kk][exp[kk]].append(int(exp[\"model_name\"]))\n",
    "                        else:\n",
    "                            parameters[kk][exp[kk]] = [int(exp[\"model_name\"])]\n",
    "\n",
    "\n",
    "                # For all methods, do cross-val and create an entry of the results\n",
    "                backbones = [net, net+\"+pgd\"]\n",
    "\n",
    "\n",
    "\n",
    "                for backbone in backbones:\n",
    "                    for robust_training in [True, False]:\n",
    "                        if robust_training:\n",
    "                            type_robust_trainings = ['linf','l1',\"certificate\",'grad']\n",
    "                        else:\n",
    "                            type_robust_trainings = ['none']\n",
    "                        for type_robust in type_robust_trainings:\n",
    "\n",
    "                            if (backbone == 'Madry' and robust_training == True) or \\\n",
    "                                (backbone == 'CNN+clipping' and robust_training == False):\n",
    "                                continue\n",
    "\n",
    "                            if robust_training==False:\n",
    "                                ids = list(set(parameters[\"backbone\"][backbone]) & \n",
    "                                           set(parameters[\"robust_training\"][False]))\n",
    "                            else:\n",
    "                                ids = list(set(parameters[\"backbone\"][backbone]) & \n",
    "                                       set(parameters[\"robust_training\"][True])&\n",
    "                                      set(parameters[\"type_robust\"][type_robust]))\n",
    "\n",
    "\n",
    "\n",
    "                            if backbone == net + '+pgd' and robust_training == True:\n",
    "                                continue\n",
    "\n",
    "                            if ids == []:\n",
    "                                continue\n",
    "                            #print(ids)\n",
    "\n",
    "\n",
    "                            # Cross-validation among learning rates and epsilons:\n",
    "                            best_acc = -1\n",
    "                            best_id = ids[0]\n",
    "                            for id in ids:\n",
    "                                if ((robust_training == False) & (backbone==net) \\\n",
    "                                    & (experiment_list[id]['training_batch_size']==256)):\n",
    "                                    continue\n",
    "                                    \n",
    "                                file_name = results_dir + experiment_list[id]['model_name'] + '/results/acc_' + 'val' + '_' + attack + '.pkl'\n",
    "                                if not os.path.isfile(file_name):\n",
    "                                    print(\"Missing!! \" + file_name)\n",
    "                                    continue\n",
    "\n",
    "                                with open(file_name, 'rb') as f:\n",
    "                                    tmp_acc = pickle.load(f)\n",
    "\n",
    "                                acc = list(tmp_acc.values())[idx_epsilon] #tmp_acc[cv_epsilon]\n",
    "                                if acc>best_acc:\n",
    "                                    best_id = id\n",
    "                                    best_acc = acc\n",
    "\n",
    "                            if best_acc == -1:\n",
    "                                continue\n",
    "\n",
    "                            if (robust_training == False) & (backbone==net):  \n",
    "                                name_legend = 'vanilla'\n",
    "                            elif backbone== net + '+pgd':\n",
    "                                name_legend = 'pgd'\n",
    "                            else:\n",
    "                                if type_robust=='certificate':\n",
    "                                    name_legend = 'RUB'\n",
    "                                elif type_robust=='linf':\n",
    "                                    name_legend = 'aRUB_Linf'\n",
    "                                elif type_robust=='grad':\n",
    "                                    name_legend = 'grad'\n",
    "                                else:\n",
    "                                    name_legend = 'aRUB_L1'\n",
    "\n",
    "                            entry = {\"learning_rate\": experiment_list[best_id]['initial_learning_rate'],\n",
    "                                     \"net\": net,\n",
    "                                     \"dataset\": dataset_name,\n",
    "                                     \"standarize\": experiment_list[best_id]['standarize'],\n",
    "                                    \"robust_training\": name_legend,\n",
    "                                    \"epsilon\": experiment_list[best_id]['epsilon'],\n",
    "                                    \"epsilon_pgd_training\": experiment_list[best_id]['epsilon_pgd_training']}\n",
    "\n",
    "                            dataset = \"test\"\n",
    "                            entry[\"attack\"] = attack\n",
    "                            entry[\"experiment_id\"] = best_id\n",
    "\n",
    "                            with open(results_dir + experiment_list[best_id]['model_name'] + '/results/acc_' + dataset + '_' + \n",
    "                                attack + '.pkl', 'rb') as f:\n",
    "                                tmp_acc = pickle.load(f)\n",
    "\n",
    "                            entry[\"accuracy\"] =  100*(list(tmp_acc.values())[idx_epsilon]) #tmp_acc[cv_epsilon]\n",
    "                            entry[\"test_epsilon\"] = cv_epsilon\n",
    "\n",
    "                            list_entries.append(entry.copy())\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(list_entries) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2669bf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc84aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}